{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNTfNGARPsUvz3a6VUTrcF+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shivani8780/Matrimonial-Profile/blob/main/matching_algo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "# Detect encoding manually if needed (e.g., 'ISO-8859-1' or 'cp1252')\n",
        "file_path = 'data_for_matching.csv'\n",
        "\n",
        "try:\n",
        "    # Attempt to load the file with explicit encoding\n",
        "    df = pd.read_csv(file_path, encoding='ISO-8859-1')  # Replace 'ISO-8859-1' with the correct encoding if necessary\n",
        "except UnicodeDecodeError as e:\n",
        "    print(f\"UnicodeDecodeError: {e}\")\n",
        "    print(\"Attempting to load the file with a different encoding.\")\n",
        "    df = pd.read_csv(file_path, encoding='utf-8', errors='replace')  # Replace problematic characters\n",
        "\n",
        "# Strip leading and trailing spaces from column names for easier handling\n",
        "df.columns = [col.strip() for col in df.columns]\n",
        "\n",
        "# Display the cleaned column names and the first few rows to confirm changes\n",
        "print(df.columns)\n",
        "print(df.head())\n",
        "\n",
        "# Function to clean height values\n",
        "def clean_height(height):\n",
        "    if pd.isnull(height):\n",
        "        return None\n",
        "    height = str(height).lower()\n",
        "    if 'feet' in height or 'ft' in height:\n",
        "        feet = re.findall(r'(\\d+)\\s*feet', height)\n",
        "        inches = re.findall(r'(\\d+)\\s*inch', height)\n",
        "        feet = int(feet[0]) if feet else 0\n",
        "        inches = int(inches[0]) if inches else 0\n",
        "        return feet * 12 + inches\n",
        "    elif '\\'' in height:\n",
        "        parts = height.split('\\'')\n",
        "        feet = int(parts[0]) if parts[0].isdigit() else 0\n",
        "        inches = int(parts[1].replace('\"', '')) if len(parts) > 1 and parts[1].replace('\"', '').isdigit() else 0\n",
        "        return feet * 12 + inches\n",
        "    else:\n",
        "        try:\n",
        "            return float(height)\n",
        "        except ValueError:\n",
        "            return None\n",
        "\n",
        "# Apply the height cleaning function\n",
        "if 'Height (In Feet)' in df.columns:\n",
        "    df['Height (In Feet)'] = df['Height (In Feet)'].apply(clean_height)\n",
        "\n",
        "# Function to clean weight values\n",
        "def clean_weight(weight):\n",
        "    if pd.isnull(weight):\n",
        "        return None\n",
        "    weight = re.sub(r'[^\\d.]', '', str(weight))  # Remove non-numeric characters except for one decimal point\n",
        "    weight = re.sub(r'\\.+', '.', weight)  # Remove extra decimal points\n",
        "    if weight.endswith('.'):\n",
        "        weight = weight[:-1]\n",
        "    try:\n",
        "        return float(weight) if weight else None\n",
        "    except ValueError:\n",
        "        return None\n",
        "\n",
        "# Apply the weight cleaning function\n",
        "if 'Weight (In KG)' in df.columns:\n",
        "    df['Weight (In KG)'] = df['Weight (In KG)'].apply(clean_weight)\n",
        "\n",
        "# Clean text fields\n",
        "df = df.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
        "\n",
        "# Save the cleaned data\n",
        "output_file = 'cleaned_data_for_matching.csv'\n",
        "df.to_csv(output_file, index=False, encoding='utf-8')\n",
        "print(f\"Data cleaning complete. Cleaned data saved to '{output_file}'.\")\n"
      ],
      "metadata": {
        "id": "4RtEKbtLbam2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d318c274-7965-46c7-a7fa-9cd9953609dd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['Name Of Candidate', 'Candidate Gender',\n",
            "       'Who is doing this Registration ?', 'MOBILE_NO', 'CITY_COUNTRY',\n",
            "       'Candidate Current Residence Area Category',\n",
            "       'Candidate Current Country', 'Visa or Residence Status Of Candidate',\n",
            "       'Date Of Birth', 'Time Of Birth', 'Birth Place', 'Height (In Feet)',\n",
            "       'Weight (In KG)', 'Highest Education Category', 'Education Details',\n",
            "       'Job/Business/Occupation Category',\n",
            "       'Details on Job / Business / Occupation',\n",
            "       'Mention your Salary or Income (optional)', 'Marriage Status', 'Nadi',\n",
            "       'Shani / Managal', 'Type Of Brahmin', 'Gotra',\n",
            "       'Candidate has Any Mental / Physical Disability or Minor Problem',\n",
            "       'Siblings Details (Brother/Sister) & Contact Number',\n",
            "       'Choice Of Education', 'Choice Of Location',\n",
            "       'Choice Of Age Gap/ Difference in Year', 'Any Other Choice'],\n",
            "      dtype='object')\n",
            "         Name Of Candidate Candidate Gender Who is doing this Registration ?  \\\n",
            "0                   Bhavik             Male                             Self   \n",
            "1              Jigar Mehta             Male                             Self   \n",
            "2            Maulik S Jani             Male                             Self   \n",
            "3               Arpan Vyas             Male                             Self   \n",
            "4  Niyati Hitendra Pandya            Female             Mother,  Bina pandya   \n",
            "\n",
            "                       MOBILE_NO                CITY_COUNTRY  \\\n",
            "0                     9879784037                    Vadodara   \n",
            "1                     9426360910                   Ahmedabad   \n",
            "2                     7600212721                   Ahmedabad   \n",
            "3  +971559948677 , +919727131991  United arab emirates Dubai   \n",
            "4                     9998987805                  Ahmedabad    \n",
            "\n",
            "  Candidate Current Residence Area Category Candidate Current Country  \\\n",
            "0  Gujarat Region (North , Central , South)                     India   \n",
            "1  Gujarat Region (North , Central , South)                     India   \n",
            "2  Gujarat Region (North , Central , South)                     India   \n",
            "3               Saurashtra - Kachchh Region                     Dubai   \n",
            "4  Gujarat Region (North , Central , South)                     India   \n",
            "\n",
            "  Visa or Residence Status Of Candidate Date Of Birth Time Of Birth  ...  \\\n",
            "0                        Indian Citizen    11-09-1989    4:45:00 AM  ...   \n",
            "1                        Indian Citizen    21-10-1977   12:45:00 PM  ...   \n",
            "2                        Indian Citizen    16-07-1991   10:47:00 AM  ...   \n",
            "3                     NRI - Work Permit    17-12-1991    5:10:00 AM  ...   \n",
            "4                        Indian Citizen     30-Mar-97    2:35:00 PM  ...   \n",
            "\n",
            "          Nadi Shani / Managal          Type Of Brahmin       Gotra  \\\n",
            "0       Aadhya      Don't Know                 Audumbar      Kasysp   \n",
            "1       Madhya   Yes (Nirdosh)   Saurahtra baj khedaval   Laukansya   \n",
            "2  I Dont Know              No  Chaturvedi Modh Brahman    Kushkush   \n",
            "3  I Dont Know              No             Modh Brahmin  Vatsyanas    \n",
            "4  I Dont Know              No                     Modh   Dharsnsya   \n",
            "\n",
            "  Candidate has Any Mental / Physical Disability or Minor Problem  \\\n",
            "0                                                 No                \n",
            "1                                                 No                \n",
            "2                                                 No                \n",
            "3                                                 NO                \n",
            "4                                                 No                \n",
            "\n",
            "  Siblings Details (Brother/Sister) & Contact Number  \\\n",
            "0                                                  1   \n",
            "1                                    Younger brother   \n",
            "2                                                Non   \n",
            "3                                           9.17E+11   \n",
            "4                  Brother perusing C.A( final year)   \n",
            "\n",
            "                                 Choice Of Education Choice Of Location  \\\n",
            "0                                                Any                Any   \n",
            "1                                           Graduate        All gujarat   \n",
            "2                                       Graduate any        Gujarat any   \n",
            "3  Everyone who dont have problem with my educati...                Any   \n",
            "4  Md,MS,Higher post candidate, classone Officer,...                All   \n",
            "\n",
            "       Choice Of Age Gap/ Difference in Year                Any Other Choice  \n",
            "0                                      30.34                              No  \n",
            "1                                   42 to 45                              No  \n",
            "2                                      26-32  Less Practical More Emotional   \n",
            "3  2 -3 yeaes younger or same age preferred                         Notrhing  \n",
            "4                                   27 to 31                        Handdome  \n",
            "\n",
            "[5 rows x 29 columns]\n",
            "Data cleaning complete. Cleaned data saved to 'cleaned_data_for_matching.csv'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-990b02abe903>:66: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
            "  df = df.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to clean date formats\n",
        "def clean_date(date):\n",
        "    try:\n",
        "        return pd.to_datetime(date, errors='coerce').strftime('%d-%m-%Y')\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "# Apply the date cleaning function\n",
        "df['Date Of Birth'] = df['Date Of Birth'].apply(clean_date)\n",
        "# Clean text fields\n",
        "df = df.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
        "\n",
        "df['Candidate has Any Mental / Physical Disability or Minor Problem'] = df['Candidate has Any Mental / Physical Disability or Minor Problem'].str.lower().str.strip()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YsGvruzWFaPS",
        "outputId": "92aa0b36-11da-480d-da34-9a4a8a8dd14b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-1e91771a864e>:4: UserWarning: Parsing dates in %d-%m-%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
            "  return pd.to_datetime(date, errors='coerce').strftime('%d-%m-%Y')\n",
            "<ipython-input-3-1e91771a864e>:4: UserWarning: Parsing dates in %d.%m.%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
            "  return pd.to_datetime(date, errors='coerce').strftime('%d-%m-%Y')\n",
            "<ipython-input-3-1e91771a864e>:4: UserWarning: Parsing dates in %d %m %Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
            "  return pd.to_datetime(date, errors='coerce').strftime('%d-%m-%Y')\n",
            "<ipython-input-3-1e91771a864e>:4: UserWarning: Parsing dates in %d/ %m/ %Y  . format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
            "  return pd.to_datetime(date, errors='coerce').strftime('%d-%m-%Y')\n",
            "<ipython-input-3-1e91771a864e>:11: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
            "  df = df.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['Choice Of Education'] = df['Choice Of Education'].str.lower().str.strip()"
      ],
      "metadata": {
        "id": "o8zSWLczG0OY"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_salary(salary):\n",
        "    if pd.isnull(salary):\n",
        "        return None\n",
        "    salary = str(salary).lower()\n",
        "    # Extract numeric values\n",
        "    numbers = re.findall(r'\\d+', salary)\n",
        "    if 'lac' in salary:\n",
        "        return int(numbers[0]) * 100000 if numbers else None\n",
        "    elif 'k' in salary:\n",
        "        return int(numbers[0]) * 1000 if numbers else None\n",
        "    elif 'cad' in salary:\n",
        "        return int(numbers[0]) * 60 if numbers else None  # Example conversion rate\n",
        "    else:\n",
        "        return int(numbers[0]) if numbers else None\n",
        "\n",
        "df['Mention your Salary or Income (optional)'] = df['Mention your Salary or Income (optional)'].apply(clean_salary)"
      ],
      "metadata": {
        "id": "AAWFwZXiHGzY"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Marriage Status'] = df['Marriage Status'].str.lower().str.strip()\n",
        "df['Education Details'] = df['Education Details'].str.lower().str.strip()"
      ],
      "metadata": {
        "id": "az41pOYnHOcp"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.fillna('Unknown', inplace=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lr_ZAV3ZHYZY",
        "outputId": "3194740f-70c7-4821-be27-a74303c3f549"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-876f1fdd0c9d>:1: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'Unknown' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
            "  df.fillna('Unknown', inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['Candidate has Any Mental / Physical Disability or Minor Problem'] = df['Candidate has Any Mental / Physical Disability or Minor Problem'].str.lower().str.strip()\n",
        "df['Choice Of Education'] = df['Choice Of Education'].str.lower().str.strip()\n",
        "df['Marriage Status'] = df['Marriage Status'].str.lower().str.strip()\n",
        "df['Shani / Managal'] = df['Shani / Managal'].str.lower().str.strip()"
      ],
      "metadata": {
        "id": "CtlMu-vCHf9K"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Gotra'] = df['Gotra'].str.lower().str.strip()\n"
      ],
      "metadata": {
        "id": "pqJPF9gYIaor"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "# Step 1: Data Loading\n",
        "def load_education_data(file_path):\n",
        "    \"\"\"\n",
        "    Load education data from various file types with encoding handling.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Support multiple file types\n",
        "        if file_path.endswith('.csv'):\n",
        "            df = pd.read_csv(file_path, encoding='utf-8', errors='replace')  # Replace invalid characters\n",
        "        elif file_path.endswith(('.xlsx', '.xls')):\n",
        "            df = pd.read_excel(file_path)\n",
        "        elif file_path.endswith('.txt'):\n",
        "            df = pd.read_csv(file_path, sep='\\t', encoding='utf-8', errors='replace')  # Replace invalid characters\n",
        "        else:\n",
        "            raise ValueError(\"Unsupported file type\")\n",
        "\n",
        "        # Strip column names to remove leading/trailing spaces\n",
        "        df.columns = df.columns.str.strip()\n",
        "\n",
        "        return df\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading data: {e}\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "# Step 2: Comprehensive Preprocessing\n",
        "class EducationPreprocessor:\n",
        "    def __init__(self, df):\n",
        "        self.df = df.copy()\n",
        "\n",
        "    def clean_text(self):\n",
        "        \"\"\"\n",
        "        Clean and standardize text\n",
        "        \"\"\"\n",
        "        # Convert to string and handle NaN\n",
        "        self.df['Education Details'] = self.df['Education Details'].astype(str)\n",
        "\n",
        "        # Convert to title case\n",
        "        self.df['Education Details'] = self.df['Education Details'].str.title()\n",
        "\n",
        "        # Remove extra whitespaces\n",
        "        self.df['Education Details'] = self.df['Education Details'].str.strip()\n",
        "\n",
        "        return self\n",
        "\n",
        "    def standardize_degrees(self):\n",
        "        \"\"\"\n",
        "        Standardize degree abbreviations and names\n",
        "        \"\"\"\n",
        "        # Dictionary of abbreviations and their full forms\n",
        "        degree_mapping = {\n",
        "            r'\\bB\\.?Com\\.?': 'Bachelor of Commerce',\n",
        "            r'\\bB\\.?E\\.?': 'Bachelor of Engineering',\n",
        "            r'\\bB\\.?Tech\\.?': 'Bachelor of Technology',\n",
        "            r'\\bM\\.?Sc\\.?': 'Master of Science',\n",
        "            r'\\bM\\.?Com\\.?': 'Master of Commerce',\n",
        "            r'\\bM\\.?B\\.?A\\.?': 'Master of Business Administration',\n",
        "            r'\\bM\\.?Tech\\.?': 'Master of Technology',\n",
        "            r'\\bPh\\.?D\\.?': 'Doctor of Philosophy',\n",
        "            r'\\bB\\.?A\\.?': 'Bachelor of Arts',\n",
        "            r'\\bB\\.?Sc\\.?': 'Bachelor of Science'\n",
        "        }\n",
        "\n",
        "        # Apply replacements\n",
        "        for pattern, replacement in degree_mapping.items():\n",
        "            self.df['Education Details'] = self.df['Education Details'].str.replace(\n",
        "                pat=pattern,\n",
        "                repl=replacement,\n",
        "                regex=True\n",
        "            )\n",
        "\n",
        "        return self\n",
        "\n",
        "    def categorize_education(self):\n",
        "        \"\"\"\n",
        "        Categorize education levels\n",
        "        \"\"\"\n",
        "        def get_education_category(education):\n",
        "            # Define category rules\n",
        "            categories = [\n",
        "                (r'(Doctor of Philosophy|Ph\\.?D)', 'Doctoral'),\n",
        "                (r'(Master of|M\\.|Post Graduate)', 'Postgraduate'),\n",
        "                (r'(Bachelor of|B\\.)', 'Undergraduate'),\n",
        "                (r'(10th|12th|High School|Ssc|Hsc)', 'High School'),\n",
        "                (r'(Diploma|Certificate)', 'Diploma')\n",
        "            ]\n",
        "\n",
        "            for pattern, category in categories:\n",
        "                if re.search(pattern, str(education), re.IGNORECASE):\n",
        "                    return category\n",
        "\n",
        "            return 'Other'\n",
        "\n",
        "        # Add education category column\n",
        "        self.df['Education_Category'] = self.df['Education Details'].apply(get_education_category)\n",
        "\n",
        "        return self\n",
        "\n",
        "    def extract_specialization(self):\n",
        "        \"\"\"\n",
        "        Extract specialization from education string\n",
        "        \"\"\"\n",
        "        def get_specialization(education):\n",
        "            # Patterns to extract specialization\n",
        "            patterns = [\n",
        "                r'in\\s(.+)$',  # Matches \"in Something\"\n",
        "                r'$$([^)]+)$$',  # Matches content within parentheses\n",
        "            ]\n",
        "\n",
        "            for pattern in patterns:\n",
        "                match = re.search(pattern, str(education), re.IGNORECASE)\n",
        "                if match:\n",
        "                    return match.group(1).strip()\n",
        "\n",
        "            return 'Not Specified'\n",
        "\n",
        "        # Add specialization column\n",
        "        self.df['Specialization'] = self.df['Education Details'].apply(get_specialization)\n",
        "\n",
        "        return self\n",
        "\n",
        "    def identify_international_education(self):\n",
        "        \"\"\"\n",
        "        Identify international education\n",
        "        \"\"\"\n",
        "        international_countries = [\n",
        "            'Canada', 'Usa', 'Uk', 'Australia', 'Germany',\n",
        "            'France', 'Netherlands', 'Singapore'\n",
        "        ]\n",
        "\n",
        "        def check_international_education(education):\n",
        "            for country in international_countries:\n",
        "                if country.lower() in str(education).lower():\n",
        "                    return country\n",
        "            return 'Domestic'\n",
        "\n",
        "        # Add international education column\n",
        "        self.df['International_Education'] = self.df['Education Details'].apply(check_international_education)\n",
        "\n",
        "        return self\n",
        "\n",
        "    def generate_insights(self):\n",
        "        \"\"\"\n",
        "        Generate insights from preprocessed data\n",
        "        \"\"\"\n",
        "        insights = {\n",
        "            'Total_Entries': len(self.df),\n",
        "            'Education_Category_Distribution': self.df['Education_Category'].value_counts(),\n",
        "            'Top_Specializations': self.df['Specialization'].value_counts().head(10),\n",
        "            'International_Education_Distribution': self.df['International_Education'].value_counts()\n",
        "        }\n",
        "\n",
        "        return insights\n",
        "\n",
        "    def preprocess(self):\n",
        "        \"\"\"\n",
        "        Execute all preprocessing steps\n",
        "        \"\"\"\n",
        "        return (self\n",
        "                .clean_text()\n",
        "                .standardize_degrees()\n",
        "                .categorize_education()\n",
        "                .extract_specialization()\n",
        "                .identify_international_education())\n",
        "\n",
        "# Main Execution\n",
        "def main():\n",
        "    # Load data\n",
        "    file_path = 'data_for_matching.csv'  # Replace with your file path\n",
        "    df = load_education_data(file_path)\n",
        "\n",
        "    # Preprocess data\n",
        "    preprocessor = EducationPreprocessor(df)\n",
        "    processed_df = preprocessor.preprocess().df\n",
        "\n",
        "    # Generate insights\n",
        "    insights = preprocessor.generate_insights()\n",
        "\n",
        "    # Print insights\n",
        "    for key, value in insights.items():\n",
        "        print(f\"\\n{key}:\")\n",
        "        print(value)\n",
        "\n",
        "    # Optional: Save processed data\n",
        "    processed_df.to_csv('processed_data.csv', index=False)\n",
        "\n",
        "    return processed_df\n",
        "\n",
        "# Run the preprocessing\n",
        "if __name__ == '__main__':\n",
        "    processed_dataframe = main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "byl0tNy8sTTu",
        "outputId": "a15e0e55-51f7-48c3-dc47-8b1aabdcbcb9"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error loading data: read_csv() got an unexpected keyword argument 'errors'\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'Education Details'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-2aa6491f4517>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[0;31m# Run the preprocessing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m     \u001b[0mprocessed_dataframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-11-2aa6491f4517>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0;31m# Preprocess data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[0mpreprocessor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEducationPreprocessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m     \u001b[0mprocessed_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;31m# Generate insights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-2aa6491f4517>\u001b[0m in \u001b[0;36mpreprocess\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    161\u001b[0m         \"\"\"\n\u001b[1;32m    162\u001b[0m         return (self\n\u001b[0;32m--> 163\u001b[0;31m                 \u001b[0;34m.\u001b[0m\u001b[0mclean_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m                 \u001b[0;34m.\u001b[0m\u001b[0mstandardize_degrees\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m                 \u001b[0;34m.\u001b[0m\u001b[0mcategorize_education\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-2aa6491f4517>\u001b[0m in \u001b[0;36mclean_text\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \"\"\"\n\u001b[1;32m     38\u001b[0m         \u001b[0;31m# Convert to string and handle NaN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Education Details'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Education Details'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;31m# Convert to title case\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4101\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4102\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4103\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4104\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/range.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    415\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHashable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 417\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    418\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_indexing_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Education Details'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from datetime import datetime\n",
        "\n",
        "def preprocess_dob(dob_series):\n",
        "    \"\"\"\n",
        "    Comprehensive date of birth preprocessing function\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    dob_series : pandas Series\n",
        "        Series containing date of birth values\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    Preprocessed DataFrame with multiple date-related columns\n",
        "    \"\"\"\n",
        "\n",
        "    def clean_and_convert_date(date_str):\n",
        "        \"\"\"\n",
        "        Advanced date cleaning and conversion\n",
        "        \"\"\"\n",
        "        if pd.isna(date_str):\n",
        "            return pd.NaT\n",
        "\n",
        "        # Convert to string and strip\n",
        "        date_str = str(date_str).strip()\n",
        "\n",
        "        # Remove extra spaces and special characters\n",
        "        date_str = re.sub(r'[^\\w\\s,.-]', '', date_str)\n",
        "\n",
        "        # Comprehensive date format handling\n",
        "        date_formats = [\n",
        "            '%d-%m-%Y',    # 11-09-1989\n",
        "            '%d/%m/%Y',    # 29/06/1998\n",
        "            '%d.%m.%Y',    # 21.07.84\n",
        "            '%d %B %Y',    # 11th December, 1993\n",
        "            '%B %d, %Y',   # April 02, 1995\n",
        "            '%d-%b-%y',    # 30-Jul-97\n",
        "            '%Y',          # 1991\n",
        "            '%m/%d/%Y',    # 11/29/1995\n",
        "            '%d %b %Y',    # 9th august 1994\n",
        "            '%d-%B-%Y',    # 11-September-1989\n",
        "            '%B %d %Y',    # September 11 1989\n",
        "        ]\n",
        "\n",
        "        # Try parsing with multiple formats\n",
        "        for fmt in date_formats:\n",
        "            try:\n",
        "                parsed_date = pd.to_datetime(date_str, format=fmt)\n",
        "                return parsed_date\n",
        "            except:\n",
        "                continue\n",
        "\n",
        "        # Fallback parsing methods\n",
        "        try:\n",
        "            # Try general parsing\n",
        "            parsed_date = pd.to_datetime(date_str, errors='coerce')\n",
        "            return parsed_date\n",
        "        except:\n",
        "            return pd.NaT\n",
        "\n",
        "    # Create DataFrame with robust conversion\n",
        "    df = pd.DataFrame()\n",
        "\n",
        "    # Ensure proper datetime conversion\n",
        "    df['original_dob'] = dob_series\n",
        "\n",
        "    # Apply advanced cleaning and conversion\n",
        "    df['cleaned_dob'] = dob_series.apply(clean_and_convert_date)\n",
        "\n",
        "    # Safely extract date components\n",
        "    def safe_extract(series, attr):\n",
        "        \"\"\"\n",
        "        Safely extract date components\n",
        "        \"\"\"\n",
        "        try:\n",
        "            return series.dt.__getattr__(attr)\n",
        "        except:\n",
        "            return pd.Series([np.nan] * len(series))\n",
        "\n",
        "    # Extract date components with error handling\n",
        "    df['year'] = safe_extract(df['cleaned_dob'], 'year')\n",
        "    df['month'] = safe_extract(df['cleaned_dob'], 'month')\n",
        "    df['day'] = safe_extract(df['cleaned_dob'], 'day')\n",
        "\n",
        "    # Age calculation with error handling\n",
        "    current_year = datetime.now().year\n",
        "    df['age'] = df['year'].apply(lambda x: current_year - x if pd.notna(x) else np.nan)\n",
        "\n",
        "    # Age group categorization\n",
        "    def categorize_age(age):\n",
        "        if pd.isna(age):\n",
        "            return 'Unknown'\n",
        "        elif age < 20:\n",
        "            return 'Under 20'\n",
        "        elif 20 <= age < 30:\n",
        "            return '20-29'\n",
        "        elif 30 <= age < 40:\n",
        "            return '30-39'\n",
        "        elif 40 <= age < 50:\n",
        "            return '40-49'\n",
        "        else:\n",
        "            return '50+'\n",
        "\n",
        "    df['age_group'] = df['age'].apply(categorize_age)\n",
        "\n",
        "    # Validate dates with comprehensive checks\n",
        "    def validate_date(row):\n",
        "        try:\n",
        "            # Check if date is not NaT\n",
        "            if pd.isnull(row['cleaned_dob']):\n",
        "                return False\n",
        "\n",
        "            # Exclude future dates\n",
        "            if row['cleaned_dob'] > pd.Timestamp.now():\n",
        "                return False\n",
        "\n",
        "            # Exclude extremely old dates\n",
        "            if pd.notna(row['year']) and row['year'] < 1940:\n",
        "                return False\n",
        "\n",
        "            return True\n",
        "        except:\n",
        "            return False\n",
        "\n",
        "    df['is_valid_date'] = df.apply(validate_date, axis=1)\n",
        "\n",
        "    # Advanced date format detection\n",
        "    def detect_date_format(date_str):\n",
        "        if pd.isna(date_str):\n",
        "            return 'Unknown'\n",
        "\n",
        "        date_str = str(date_str)\n",
        "\n",
        "        formats = [\n",
        "            (r'^\\d{2}-\\d{2}-\\d{4}$', 'DD-MM-YYYY'),\n",
        "            (r'^\\d{1,2}/\\d{1,2}/\\d{4}$', 'DD/MM/YYYY'),\n",
        "            (r'^\\d{1,2}\\.\\d{1,2}\\.\\d{2,4}$', 'DD.MM.YYYY'),\n",
        "            (r'^\\w+\\s\\d{1,2},?\\s\\d{4}$', 'Month DD, YYYY'),\n",
        "            (r'^\\d{1,2}-\\w{3}-\\d{2}$', 'DD-Mon-YY'),\n",
        "            (r'^\\d{4}$', 'YYYY'),\n",
        "        ]\n",
        "\n",
        "        for pattern, format_name in formats:\n",
        "            if re.match(pattern, date_str):\n",
        "                return format_name\n",
        "\n",
        "        return 'Other'\n",
        "\n",
        "    df['date_format'] = dob_series.apply(detect_date_format)\n",
        "\n",
        "    return df\n",
        "\n",
        "def main():\n",
        "    # Example usage with error handling\n",
        "    try:\n",
        "        # Option 1: Direct list input\n",
        "        dob_series = pd.Series([\n",
        "            '11-09-1989', '21-10-1977', '16-07-1991',\n",
        "            '30-Mar-97', 'June 13 1995', '27051998'\n",
        "        ])\n",
        "\n",
        "        # Preprocess dates\n",
        "        preprocessed_df = preprocess_dob(dob_series)\n",
        "\n",
        "        # Save the output to a CSV file\n",
        "        output_file = 'preprocessed_dob.csv'\n",
        "        preprocessed_df.to_csv(output_file, index=False)\n",
        "        print(f\"\\nPreprocessed data saved to {output_file}\")\n",
        "\n",
        "        # Display results\n",
        "        print(\"\\nPreprocessed Date of Birth Data:\")\n",
        "        print(preprocessed_df)\n",
        "\n",
        "        # Save the output to a CSV file\n",
        "        output_file = 'preprocessed_dob.csv'\n",
        "        preprocessed_df.to_csv(output_file, index=False)\n",
        "        print(f\"\\nPreprocessed data saved to {output_file}\")\n",
        "\n",
        "        # Analysis\n",
        "        print(\"\\nAge Group Distribution:\")\n",
        "        print(preprocessed_df['age_group'].value_counts())\n",
        "\n",
        "        print(\"\\nDate Format Distribution:\")\n",
        "        print(preprocessed_df['date_format'].value_counts())\n",
        "\n",
        "        print(\"\\nValid Dates:\")\n",
        "        print(preprocessed_df['is_valid_date'].value_counts())\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4GhllafVuGDP",
        "outputId": "daec39c8-6da8-412a-8f53-b2e85d234a5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Preprocessed Date of Birth Data:\n",
            "   original_dob cleaned_dob  year  month  day  age age_group  is_valid_date  \\\n",
            "0    11-09-1989  1989-09-11   NaN    NaN  NaN  NaN   Unknown           True   \n",
            "1    21-10-1977  1977-10-21   NaN    NaN  NaN  NaN   Unknown           True   \n",
            "2    16-07-1991  1991-07-16   NaN    NaN  NaN  NaN   Unknown           True   \n",
            "3     30-Mar-97  1997-03-30   NaN    NaN  NaN  NaN   Unknown           True   \n",
            "4  June 13 1995  1995-06-13   NaN    NaN  NaN  NaN   Unknown           True   \n",
            "5      27051998         NaT   NaN    NaN  NaN  NaN   Unknown          False   \n",
            "\n",
            "      date_format  \n",
            "0      DD-MM-YYYY  \n",
            "1      DD-MM-YYYY  \n",
            "2      DD-MM-YYYY  \n",
            "3       DD-Mon-YY  \n",
            "4  Month DD, YYYY  \n",
            "5           Other  \n",
            "\n",
            "Age Group Distribution:\n",
            "age_group\n",
            "Unknown    6\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Date Format Distribution:\n",
            "date_format\n",
            "DD-MM-YYYY        3\n",
            "DD-Mon-YY         1\n",
            "Month DD, YYYY    1\n",
            "Other             1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Valid Dates:\n",
            "is_valid_date\n",
            "True     5\n",
            "False    1\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NL5St_TvuI_T"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}